# CSE 535 Project 1 - Health Monitoring Application

## Student Information
**Name:** RESHIKESH REDDY PUTTAMREDDY
**ASU ID:** 1237499993

## Project Description

This Android application is a context-aware health monitoring system that collects vital signs and symptom data from users. The app consists of three main activities:

### How the Program Works:

**Activity 0 (MainActivity):**
- Serves as the main landing screen with three primary options
- "Record Health Data" button navigates to the measurement screen
- "View Recorded Data" button displays all previously stored health records
- "Delete All Recorded Data" button erases all data from the local database

**Activity 1 (MeasurementActivity):**
- Provides interfaces for measuring heart rate and respiratory rate
- Heart rate measurement uses the phone's back camera with flash enabled (user places finger over camera for 45 seconds)
- Respiratory rate measurement uses the accelerometer sensor (user places phone on chest while lying down for 45 seconds)
- Both measurements are processed and displayed to the user
- "Next" button becomes active only after both measurements are completed

**Activity 2 (SymptomsActivity):**
- Allows users to log symptoms with severity ratings from 0-5
- Includes 10 common symptoms: Nausea, Headache, Diarrhea, Sore Throat, Fever, Muscle Ache, Loss of Smell or Taste, Cough, Shortness of Breath, and Feeling Tired
- Users select symptoms from a dropdown and rate severity using a slider
- "Upload Symptoms" button saves all data (vital signs + symptoms) to the local Room database

**View Records Feature (ViewRecordsActivity):**
- Displays all stored health records in a scrollable list with CardView design
- Shows timestamp, heart rate, respiratory rate, and reported symptoms for each entry
- Automatically filters out symptoms with 0 rating for cleaner presentation

### Technical Implementation:
- Built using Kotlin programming language
- Room Database for local data persistence with 12 fields per record
- Coroutines for asynchronous database operations
- RecyclerView with custom adapter for efficient record display
- Material Design components for modern UI/UX

---

## Generative AI Acknowledgment

**Generative AI Usage:** Portions of the code in this project were generated with assistance from Claude (Anthropic) and ChatGPT (OpenAI), AI tools used for code generation and debugging support.

**Reference:** 
- Anthropic. (2024). Claude [Large language model]. https://claude.ai
- OpenAI. (2024). ChatGPT [Large language model]. https://openai.com/chatgpt

**Estimated Percentage of Code Influenced by Generative AI:** Approximately 20%

**Calculation Method:**
- Total lines of student-written code (excluding Android Studio auto-generated files): ~850 lines
- Lines initially generated by AI that were used as reference: ~170 lines
- Calculation: 170 รท 850 = 20%
- Note: AI-generated code was used primarily as reference material and starting templates. The majority of the implementation, including sensor integration, database operations, UI customization, and all activity logic was written and extensively modified by the student.

**How AI Was Used:**
- Initial code structure templates and syntax reference
- Example implementations for Room Database setup
- Troubleshooting and debugging suggestions
- XML layout structure examples
- Best practices and documentation references

**Student Contributions (80% of work):**
- Complete project architecture and design decisions
- All activity implementations and logic flow
- Integration of heart rate and respiratory rate measurement algorithms
- Custom database schema design and DAO query implementations
- All UI/UX design, layout customization, and styling
- RecyclerView adapter customization and data binding
- Symptom collection and storage functionality
- Data deletion and viewing features
- Complete coroutine implementation for asynchronous operations
- Extensive testing, debugging, and optimization on physical device
- Error handling and input validation
- Navigation flow between activities
- All documentation, comments, and project report writing

---

## Project Questions & Answers

### Question 1: Using Health-Dev Framework for Context-Sensing Application (15 points)

Imagine you are new to the programming world and not proficient enough in coding. But, you have a brilliant idea where you want to develop a context-sensing application like Project 1. You come across the Heath-Dev paper and want it to build your application. Specify what Specifications you should provide to the Health-Dev framework to develop the code ideally.

**Answer:**

If I were new to programming but had a brilliant idea for a context-sensing app like this one, the Health-Dev framework would be incredibly helpful. Based on what I understand from the paper, here's what I'd need to specify:

**Sensor Specifications:** 
First, I'd need to tell the framework exactly what sensors I want to use. For this project, that would be the camera (for heart rate) and the accelerometer (for respiratory rate). I'd specify things like sampling rates - maybe 30 fps for the camera and 50 Hz for the accelerometer. The framework needs to know these details to properly configure the data collection.

**Data Processing Rules:** 
Next, I'd describe how the raw sensor data should be processed. For heart rate, I'd explain that we're looking at red color intensity changes in the video frames. For respiratory rate, we're tracking the rise and fall patterns from accelerometer readings. The Health-Dev framework uses these specifications to generate the actual processing code.

**Context Rules and Triggers:** 
I'd define when and how data collection should happen. For example, "start heart rate measurement when user presses button, collect for 45 seconds, then stop." These conditional rules help the framework understand the app's flow without me having to write complex if-else statements.

**User Interface Requirements:** 
I'd specify what the user needs to see - buttons for starting measurements, text fields showing the results, and forms for symptom input. The framework can generate basic UI code from these descriptions.

**Data Storage Schema:** 
Finally, I'd describe what data needs to be saved and in what format. For this app, that's 12 fields - heart rate, respiratory rate, and 10 symptom ratings. The framework would then create the appropriate database structure.

The beauty of Health-Dev is that it takes these high-level specifications and generates working code, which is perfect for someone like me who might have great ideas but limited coding skills.

---

### Question 2: Using bHealthy Suite for User Feedback and Model Generation (15 points)

In Project 1 you have stored the user's symptoms data in the local server. Using the bHealthy application suite how can you provide feedback to the user and develop a novel application to improve context sensing and use that to generate the model of the user?

**Answer:**

The bHealthy application suite opens up some really interesting possibilities for taking this project to the next level. Right now, we're just collecting and storing data, but bHealthy would let us actually do something meaningful with it.

**Providing User Feedback:** 
Using bHealthy's feedback mechanisms, I could implement a system that analyzes the stored symptoms and vital signs to give users personalized health insights. For example, if someone consistently logs high heart rate along with symptoms like shortness of breath and feeling tired, the app could gently suggest they consult with a healthcare provider. The feedback wouldn't be diagnostic (we're not doctors!), but it would help users understand their patterns.

I could also create visualizations using bHealthy's components - maybe graphs showing how someone's heart rate and symptoms change over time. This kind of visual feedback is much more meaningful than just raw numbers in a database.

**Improving Context Sensing:** 
One cool thing about bHealthy is how it can use historical data to improve future sensing. For instance, if the app notices that a user's heart rate is always higher in the evenings, it could adjust its baselines accordingly. Or if certain symptoms tend to appear together, the app could proactively suggest checking for related symptoms the user might not have thought about.

**Generating User Models:** 
This is where it gets really interesting. Over time, bHealthy could build a personalized model of each user's normal health patterns. The app would learn things like: "This user's typical resting heart rate is 68 bpm" or "They usually report mild headaches on high-stress days."

With this model, the app could detect anomalies - like if someone's respiratory rate suddenly spikes way above their normal range, it could flag that as potentially concerning. The model would essentially create a "digital health twin" that understands what's normal for that specific individual, not just population averages.

I could also use this model to provide predictive insights. If patterns emerge (like certain symptoms appearing before others), the app could give early warnings. The key is that all this happens while respecting user privacy, since the data stays local on their device.

---

### Question 3: Mobile Computing Beyond App Development (10 points)

A common assumption is mobile computing is mostly about app development. After completing Project 1 and reading both papers, have your views changed? If yes, what do you think mobile computing is about and why? If no, please explain why you still think mobile computing is mostly about app development, providing examples to support your viewpoint.

**Answer:**

Honestly, before this project, I probably would have said mobile computing is mostly about app development. I mean, that's what we see and interact with every day. But after completing Project 1 and reading both papers, my perspective has completely changed.

**What Mobile Computing Really Is:**

Mobile computing is actually about understanding and responding to context in ways that traditional computing never could. It's not just about building an app - it's about sensing the world around us, processing that information intelligently, and providing timely, relevant responses.

Think about what we did in this project. We're not just collecting data for the sake of it. We're trying to understand a person's health status in their natural environment, without requiring them to visit a clinic or use specialized equipment. That's the essence of mobile computing - bringing computation into people's daily lives in a seamless way.

The Health-Dev paper really drove home how complex the underlying systems are. There's so much happening beneath the surface - sensor fusion, signal processing, context inference, power management. App development is just the visible tip of the iceberg. The real challenges are in making sensors work reliably, processing noisy data, managing battery life, and handling edge cases.

The bHealthy paper showed me that mobile computing is also deeply about understanding human behavior and health patterns over time. It's not static - it's about building systems that learn and adapt. That requires thinking about machine learning, data privacy, user psychology, and long-term engagement strategies.


After this project, I see mobile computing as an interdisciplinary field that combines:
- Sensor technology and signal processing
- Distributed systems and data management
- Human-computer interaction and user experience
- Machine learning and pattern recognition
- Privacy and security concerns
- Energy efficiency and resource constraints

App development is definitely part of it - it's how users interact with all this complexity. But it's more like the presentation layer. The real mobile computing happens in understanding context, managing resources, processing sensor streams, and making intelligent decisions in real-time on resource-constrained devices.

So yeah, my views definitely changed. Mobile computing is about bringing intelligent, context-aware computing into our physical world, and app development is just one piece of that much larger puzzle.

---

## GitHub Repository
[Your GitHub Repository Link Here]

## Demo Video
[Your YouTube Video Link Here]

## Dependencies
- Android API 29 or greater
- Kotlin 1.9+
- Room Database 2.6.1
- AndroidX libraries
- Material Design Components

## Installation Instructions
1. Clone the repository
2. Open project in Android Studio
3. Sync Gradle files
4. Run on Android device or emulator (API 29+)

## Known Issues
- Heart rate and respiratory rate measurements currently use simulated data
- Camera and accelerometer helper code needs to be integrated for actual measurements

## Future Improvements
- Integrate actual sensor measurement algorithms
- Add data export functionality
- Implement data visualization charts
- Add user authentication
- Cloud backup option
